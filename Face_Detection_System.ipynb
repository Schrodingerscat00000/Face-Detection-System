{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zAkSnByUHfNblZvo26Oq7oIv3ZPAri7v",
      "authorship_tag": "ABX9TyMjUvmTA1vGfps234mCBQOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Schrodingerscat00000/Face-Detection-System/blob/main/Face_Detection_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i0WiAVnvfG7c",
        "outputId": "d27bd22e-8a27-4879-9d0d-627a70a6aad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.11/dist-packages (1.15.1)\n",
            "Requirement already satisfied: opencv-python-headless==4.7.0.72 in /usr/local/lib/python3.11/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.17.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (10.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.12.0)\n",
            "Requirement already satisfied: deep_sort_realtime in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless==4.7.0.72) (2.2.6)\n",
            "Collecting numpy>=1.21.2 (from opencv-python-headless==4.7.0.72)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.32.3)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.74.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
            "Requirement already satisfied: portalocker<4.0,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (3.2.0)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (5.29.5)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.11.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from deep_sort_realtime) (1.16.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from deep_sort_realtime) (4.12.0.88)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python (from deep_sort_realtime)\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, opencv-python\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "albumentations 2.0.8 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.7.0.72 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 opencv-python-4.11.0.86\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "bc0211de64a541f08e7046d4847dfebf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "!pip install facenet-pytorch qdrant-client opencv-python-headless==4.7.0.72 torch torchvision pillow tqdm faiss-cpu deep_sort_realtime\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDFXU_2DqCzw",
        "outputId": "cc39899d-0fee-47ae-ea3a-b26024c5a7df"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.179-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (10.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.17.2)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.15-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.82)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.3.179-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.15-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.179 ultralytics-thop-2.0.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import uuid\n",
        "import time\n",
        "import json\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Face libs\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "\n",
        "# Qdrant client\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http import models as qmodels\n",
        "\n",
        "# deep sort\n",
        "try:\n",
        "    from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "    DEEPSORT_AVAILABLE = True\n",
        "except Exception as e:\n",
        "    print(\"deep_sort_realtime import failed:\", e)\n",
        "    DEEPSORT_AVAILABLE = False\n",
        "\n",
        "# FAISS fallback\n",
        "try:\n",
        "    import faiss\n",
        "    FAISS_AVAILABLE = True\n",
        "except Exception:\n",
        "    FAISS_AVAILABLE = False"
      ],
      "metadata": {
        "id": "t2Fp-6V8i7rw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the YOLOv8-face weights (nano). This uses the repo releases URL.\n",
        "!wget -O yolov8m-face-lindevs.pt \\\n",
        "  https://github.com/lindevs/yolov8-face/releases/download/1.0.1/yolov8n-face-lindevs.pt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbtJOH3Xr6EP",
        "outputId": "598ecfde-3915-49d2-dbb2-006b56b5fb02"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-17 06:20:44--  https://github.com/lindevs/yolov8-face/releases/download/1.0.1/yolov8n-face-lindevs.pt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/726537896/774e6a09-ecf4-443a-a361-3d0debb0086f?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-08-17T07%3A19%3A26Z&rscd=attachment%3B+filename%3Dyolov8n-face-lindevs.pt&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-08-17T06%3A19%3A25Z&ske=2025-08-17T07%3A19%3A26Z&sks=b&skv=2018-11-09&sig=JzE%2Fml6TZPeGaiTx9mnB7HB4N5sC4aRf3tpfveLzMdU%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1NTQxMTk0NCwibmJmIjoxNzU1NDExNjQ0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.NH_SFT6lkXQNslBkVIewxw-lNBC2c7NQznWw-yFnjgk&response-content-disposition=attachment%3B%20filename%3Dyolov8n-face-lindevs.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-08-17 06:20:44--  https://release-assets.githubusercontent.com/github-production-release-asset/726537896/774e6a09-ecf4-443a-a361-3d0debb0086f?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-08-17T07%3A19%3A26Z&rscd=attachment%3B+filename%3Dyolov8n-face-lindevs.pt&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-08-17T06%3A19%3A25Z&ske=2025-08-17T07%3A19%3A26Z&sks=b&skv=2018-11-09&sig=JzE%2Fml6TZPeGaiTx9mnB7HB4N5sC4aRf3tpfveLzMdU%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1NTQxMTk0NCwibmJmIjoxNzU1NDExNjQ0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.NH_SFT6lkXQNslBkVIewxw-lNBC2c7NQznWw-yFnjgk&response-content-disposition=attachment%3B%20filename%3Dyolov8n-face-lindevs.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6281321 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘yolov8m-face-lindevs.pt’\n",
            "\n",
            "yolov8m-face-lindev 100%[===================>]   5.99M  25.4MB/s    in 0.2s    \n",
            "\n",
            "2025-08-17 06:20:44 (25.4 MB/s) - ‘yolov8m-face-lindevs.pt’ saved [6281321/6281321]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOLO_WEIGHTS = \"yolov8m-face-lindevs.pt\"\n",
        "from ultralytics import YOLO\n",
        "yolo_model = YOLO(YOLO_WEIGHTS)\n"
      ],
      "metadata": {
        "id": "hpvACH5yqT2n"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick verify\n",
        "import os\n",
        "ENROLL_DIR = \"/content/drive/MyDrive/Face Detection System/Liverpool Players\"\n",
        "print(\"Exists?\", os.path.exists(ENROLL_DIR))\n",
        "print(\"Sample list:\", sorted(os.listdir(ENROLL_DIR))[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNm8xmn_NPaF",
        "outputId": "2f84c413-a845-4678-9e17-9a1bc650e9a3"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists? True\n",
            "Sample list: ['alewx arnold.png', 'alex isak.png', 'alisson becker.jpg', 'arne slot.jpeg', 'arne slot.jpg', 'ben sesko.png', 'cody gakpo.png', 'cole palmer.png', 'diogo jota.jpg', 'dom szoboszlai.png', 'erling haaland.jpg', 'fred chiesa.jpg', 'luis diaz.jpg', 'mo salah.jpg', 'moh salah.jpeg', 'moh salah.png', 'vvd.jpeg', 'vvd.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIG / TUNABLES\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "COLLECTION_NAME = \"First\"\n",
        "VECTOR_SIZE = 512\n",
        "METADATA_DB = \"metadata.sqlite\"\n",
        "ENROLL_DIR = \"/content/drive/MyDrive/Face Detection System/Liverpool Players\"\n",
        "SNAPSHOT_DIR = \"snapshots\"\n",
        "FRAME_SKIP = 3\n",
        "EMBED_EVERY_N_FRAMES = 10\n",
        "MATCH_THRESHOLD = 0.6 # Lowered the match threshold further"
      ],
      "metadata": {
        "id": "QbqzSDoIkbgS"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['QDRANT_URL'] = \"https://381ea9cc-bc60-4ce0-9ab4-8606feafd077.us-west-1-0.aws.cloud.qdrant.io\"\n",
        "os.environ['QDRANT_API_KEY'] = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.gSja_os0KGQwv9QoG2AtPjRANt_Wba3O9LugvukBZLg\"\n",
        "# Then re-run the qdrant init cell you used earlier\n"
      ],
      "metadata": {
        "id": "wD4dySYZPmbd"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http import models as qmodels\n",
        "import os\n",
        "\n",
        "\n",
        "# qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY) # Removed this line\n",
        "\n",
        "COLL = \"First\"\n",
        "VECTOR_SIZE = 512\n",
        "\n",
        "# create collection if missing\n",
        "try:\n",
        "    qdrant_client = QdrantClient(url=os.environ.get('QDRANT_URL'), api_key=os.environ.get('QDRANT_API_KEY')) # Initialize client here\n",
        "    qdrant_client.get_collection(COLL)\n",
        "    print(f\"Collection '{COLL}' already exists.\")\n",
        "except Exception:\n",
        "    print(f\"Collection '{COLL}' not found. Creating it.\")\n",
        "    qdrant_client.create_collection(collection_name=COLL,\n",
        "                                    vectors_config=qmodels.VectorParams(size=VECTOR_SIZE,\n",
        "                                                                       distance=qmodels.Distance.COSINE))\n",
        "# show counts\n",
        "cols = qdrant_client.get_collections()\n",
        "print(\"Collections on server:\", [c.name for c in cols.collections])\n",
        "info = qdrant_client.get_collection(COLL)\n",
        "print(f\"'{COLL}' points_count:\", info.points_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh-4qEmKNOk9",
        "outputId": "9f517c60-d01f-4fb9-d5fb-66f4ad14e97e"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'First' already exists.\n",
            "Collections on server: ['First']\n",
            "'First' points_count: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# METADATA DB (sqlite)\n",
        "# ------------------------------\n",
        "def init_metadata_db(db_path=METADATA_DB):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS users (\n",
        "      user_id TEXT PRIMARY KEY,\n",
        "      name TEXT,\n",
        "      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "    )\"\"\")\n",
        "    cur.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS images (\n",
        "      image_id TEXT PRIMARY KEY,\n",
        "      user_id TEXT,\n",
        "      path TEXT,\n",
        "      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "    )\"\"\")\n",
        "    cur.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS access_logs (\n",
        "      log_id TEXT PRIMARY KEY,\n",
        "      ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "      camera_id TEXT,\n",
        "      user_id TEXT,\n",
        "      match_score REAL,\n",
        "      decision TEXT,\n",
        "      snapshot_path TEXT,\n",
        "      extra JSON\n",
        "    )\"\"\")\n",
        "    conn.commit()\n",
        "    return conn\n",
        "\n",
        "meta_conn = init_metadata_db()"
      ],
      "metadata": {
        "id": "bXPS2eW7mjd4"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QDRANT init (same as earlier)\n",
        "# ------------------------------\n",
        "def init_qdrant_client(url=os.environ.get('QDRANT_URL'), api_key=os.environ.get('QDRANT_API_KEY'), collection_name=\"First\"):\n",
        "    client = QdrantClient(url=url, api_key=api_key)\n",
        "    try:\n",
        "        # Check if collection exists\n",
        "        client.get_collection(collection_name)\n",
        "        print(f\"Collection '{collection_name}' already exists.\")\n",
        "    except Exception:\n",
        "        print(f\"Collection '{collection_name}' not found. Creating...\")\n",
        "        client.create_collection(collection_name=collection_name,\n",
        "                                 vectors_config=qmodels.VectorParams(size=VECTOR_SIZE, distance=qmodels.Distance.COSINE))\n",
        "        print(f\"Collection '{collection_name}' created.\")\n",
        "        # Verify creation\n",
        "        client.get_collection(collection_name)\n",
        "        print(f\"Collection '{collection_name}' verified.\")\n",
        "\n",
        "    return client\n",
        "\n",
        "use_qdrant = True\n",
        "qdrant_client = None\n",
        "try:\n",
        "    qdrant_client = init_qdrant_client()\n",
        "    print(\"Qdrant connected:\", os.environ.get('QDRANT_URL')) # Use the environment variable here\n",
        "except Exception as e:\n",
        "    print(\"Qdrant init failed:\", e)\n",
        "    use_qdrant = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-I4h3pMmtRv",
        "outputId": "ac902c37-eb28-4e13-bad8-d11ea1e61795"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'First' already exists.\n",
            "Qdrant connected: https://381ea9cc-bc60-4ce0-9ab4-8606feafd077.us-west-1-0.aws.cloud.qdrant.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL init\n",
        "print(\"Device:\", DEVICE)\n",
        "mtcnn = MTCNN(image_size=160, margin=8, keep_all=True, device=DEVICE)\n",
        "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(DEVICE)\n",
        "\n",
        "def get_embedding_from_pil(pil_img: Image.Image) -> np.ndarray:\n",
        "    \"\"\"Return L2 normalized 512-d embedding from PIL image (160x160 expected).\"\"\"\n",
        "    with torch.no_grad():\n",
        "        img = pil_img.convert('RGB')\n",
        "        arr = np.asarray(img).astype(np.float32)\n",
        "        tensor = torch.tensor(arr).permute(2,0,1).unsqueeze(0).to(DEVICE)\n",
        "        tensor = (tensor - 127.5) / 128.0\n",
        "        emb = resnet(tensor).squeeze().cpu().numpy()\n",
        "        emb = emb / np.linalg.norm(emb)\n",
        "        return emb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH099TDSnzkX",
        "outputId": "19164b55-a397-4bfc-d6b2-43af541eddbb"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enrollment function (modified to handle images directly in ENROLL_DIR and convert to RGB)\n",
        "from qdrant_client.http import models as rest_models\n",
        "import uuid\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Use int IDs for Qdrant (instead of UUID strings)\n",
        "global_point_id = 0\n",
        "\n",
        "def enroll_from_folder(enroll_dir=ENROLL_DIR, q_client=None, collection_name=COLLECTION_NAME, db_conn=meta_conn):\n",
        "    global global_point_id  # Declare global_point_id as global\n",
        "\n",
        "    cur = db_conn.cursor()\n",
        "\n",
        "    # Create debug directory for cropped faces\n",
        "    debug_dir = \"debug_cropped_faces\"\n",
        "    Path(debug_dir).mkdir(exist_ok=True)\n",
        "\n",
        "    # Clear existing data in Qdrant collection before enrolling\n",
        "    if use_qdrant and qdrant_client is not None:\n",
        "        try:\n",
        "            qdrant_client.recreate_collection(\n",
        "                collection_name=collection_name,\n",
        "                vectors_config=qmodels.VectorParams(size=VECTOR_SIZE, distance=qmodels.Distance.COSINE)\n",
        "            )\n",
        "            print(f\"Collection '{collection_name}' recreated.\")\n",
        "            global_point_id = 0 # Reset global_point_id after recreating collection\n",
        "        except Exception as e:\n",
        "            print(f\"Error recreating collection '{collection_name}': {e}\")\n",
        "            return # Stop enrollment if collection cannot be recreated\n",
        "\n",
        "\n",
        "    # Delete existing data in SQLite DB\n",
        "    try:\n",
        "        cur.execute(\"DELETE FROM users\")\n",
        "        cur.execute(\"DELETE FROM images\")\n",
        "        cur.execute(\"DELETE FROM access_logs\")\n",
        "        db_conn.commit()\n",
        "        print(\"Cleared existing data in SQLite database.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error clearing SQLite database: {e}\")\n",
        "        return # Stop enrollment if DB cannot be cleared\n",
        "\n",
        "\n",
        "    user_data = {} # Store embeddings and image paths per user name\n",
        "\n",
        "    for img_path in sorted(Path(enroll_dir).glob(\"*.*\")):\n",
        "        if not img_path.is_file() or img_path.name.startswith('.'):\n",
        "            continue\n",
        "\n",
        "        # Extract user name from filename (assuming format \"user name.extension\")\n",
        "        user_name = img_path.stem # Get filename without extension\n",
        "        if not user_name:\n",
        "            print(f\"Skipping {img_path}: cannot extract user name from filename.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            # Convert image to RGB if it's not (handles PNG with alpha)\n",
        "            if img.mode != 'RGB':\n",
        "                img = img.convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(\"open failed\", img_path, e); continue\n",
        "\n",
        "        # detect first face (use mtcnn)\n",
        "        boxes, probs = mtcnn.detect(img)\n",
        "        if boxes is None:\n",
        "            print(\"no face for\", img_path); continue\n",
        "\n",
        "        # take top-prob face\n",
        "        best_idx = int(np.argmax(probs))\n",
        "        x1,y1,x2,y2 = [int(v) for v in boxes[best_idx]]\n",
        "        aligned = img.crop((x1,y1,x2,y2)).resize((160,160))\n",
        "\n",
        "        # Save the cropped and resized face for debugging\n",
        "        debug_filename = f\"{debug_dir}/{user_name}_{img_path.name}\"\n",
        "        aligned.save(debug_filename)\n",
        "        print(f\"Saved cropped face to {debug_filename}\")\n",
        "\n",
        "        emb = get_embedding_from_pil(aligned)\n",
        "\n",
        "        if user_name not in user_data:\n",
        "            user_data[user_name] = {\"embeddings\": [], \"image_paths\": []}\n",
        "        user_data[user_name][\"embeddings\"].append(emb)\n",
        "        user_data[user_name][\"image_paths\"].append(str(img_path))\n",
        "\n",
        "    # Process collected data per user\n",
        "    for user_name, data in user_data.items():\n",
        "        user_id = str(uuid.uuid4())\n",
        "        print(\"Enrolling:\", user_name, \"->\", user_id)\n",
        "\n",
        "        # Insert user into DB\n",
        "        try:\n",
        "            cur.execute(\"INSERT INTO users (user_id, name) VALUES (?,?)\", (user_id, user_name))\n",
        "        except Exception as e:\n",
        "            print(f\"Error inserting user {user_name} into DB: {e}\")\n",
        "            continue # Skip this user if DB insertion fails\n",
        "\n",
        "        # Process individual images and their embeddings\n",
        "        for emb, img_path in zip(data[\"embeddings\"], data[\"image_paths\"]):\n",
        "            image_id = str(uuid.uuid4())\n",
        "            try:\n",
        "                cur.execute(\"INSERT INTO images (image_id, user_id, path) VALUES (?,?,?)\", (image_id, user_id, img_path))\n",
        "            except Exception as e:\n",
        "                print(f\"Error inserting image {img_path} for user {user_name} into DB: {e}\")\n",
        "                # Continue to the next image even if DB insertion fails for one image\n",
        "\n",
        "            if use_qdrant and qdrant_client is not None:\n",
        "                try:\n",
        "                    global_point_id += 1 # Increment global_point_id\n",
        "                    qdrant_client.upsert(\n",
        "                        collection_name=collection_name,\n",
        "                        points=[\n",
        "                            qmodels.PointStruct(\n",
        "                                id=global_point_id,  # Use int id\n",
        "                                vector=emb.tolist(),\n",
        "                                payload={\n",
        "                                    \"user_id\": user_id,\n",
        "                                    \"user_name\": user_name,\n",
        "                                    \"source_image\": img_path,\n",
        "                                    \"type\": \"face\" # Add type for clarity\n",
        "                                }\n",
        "                            )\n",
        "                        ]\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    print(\"qdrant upsert image failed\", e)\n",
        "\n",
        "        # Compute and upsert centroid embedding for the user\n",
        "        if data[\"embeddings\"]: # Only compute centroid if there are embeddings\n",
        "            avg = np.mean(np.stack(data[\"embeddings\"], axis=0), axis=0)\n",
        "            avg = avg / np.linalg.norm(avg)\n",
        "            if use_qdrant and qdrant_client is not None:\n",
        "                try:\n",
        "                    global_point_id += 1 # Increment global_point_id for centroid\n",
        "                    qdrant_client.upsert(\n",
        "                        collection_name=collection_name,\n",
        "                        points=[\n",
        "                            qmodels.PointStruct(\n",
        "                                id=global_point_id, # Use int id\n",
        "                                vector=avg.tolist(),\n",
        "                                payload={\n",
        "                                    \"user_id\": user_id,\n",
        "                                    \"user_name\": user_name,\n",
        "                                    \"type\": \"centroid\" # Add type for clarity\n",
        "                                }\n",
        "                            )\n",
        "                        ]\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    print(\"qdrant upsert centroid failed\", e)\n",
        "\n",
        "    db_conn.commit() # Commit outside the loop for better performance\n",
        "    print(\"Enrollment done.\")"
      ],
      "metadata": {
        "id": "655m1UtZn-Nf"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fba933c",
        "outputId": "0b6be310-dd54-457a-b022-696274e43fbb"
      },
      "source": [
        "if not use_qdrant:\n",
        "    print(\"Qdrant is not being used. Skipping Qdrant collection check.\")\n",
        "else:\n",
        "    print(\"Connecting to Qdrant and checking collection status...\")\n",
        "    try:\n",
        "        # List all collections\n",
        "        collections_response = qdrant_client.get_collections()\n",
        "        print(\"Collections in Qdrant:\")\n",
        "        for collection in collections_response.collections:\n",
        "            print(f\"- {collection.name}\")\n",
        "\n",
        "        # Get information about the face collection\n",
        "        try:\n",
        "            face_collection_info = qdrant_client.get_collection(collection_name=COLLECTION_NAME)\n",
        "            print(f\"\\nInformation for collection '{COLLECTION_NAME}':\")\n",
        "            print(f\"Number of points: {face_collection_info.points_count}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error getting info for collection '{COLLECTION_NAME}': {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error connecting to Qdrant or listing collections: {e}\")\n"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to Qdrant and checking collection status...\n",
            "Collections in Qdrant:\n",
            "- First\n",
            "\n",
            "Information for collection 'First':\n",
            "Number of points: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"use_qdrant:\", use_qdrant)\n",
        "print(\"qdrant_client:\", type(qdrant_client))\n",
        "try:\n",
        "    print(\"Collections:\", [c.name for c in qdrant_client.get_collections().collections])\n",
        "except Exception as e:\n",
        "    print(\"Qdrant connection error:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19UjBjALRI4L",
        "outputId": "f2ab873f-a15b-4c71-c96e-49028dbe7d15"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use_qdrant: True\n",
            "qdrant_client: <class 'qdrant_client.qdrant_client.QdrantClient'>\n",
            "Collections: ['First']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# call the improved function\n",
        "enroll_from_folder(enroll_dir=ENROLL_DIR, q_client=qdrant_client, collection_name=\"First\", db_conn=meta_conn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vTBrrdKRMo0",
        "outputId": "007eb416-3087-41f4-edc7-72d9be1780db"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-112905981.py:24: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant_client.recreate_collection(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'First' recreated.\n",
            "Cleared existing data in SQLite database.\n",
            "Saved cropped face to debug_cropped_faces/alewx arnold_alewx arnold.png\n",
            "Saved cropped face to debug_cropped_faces/alex isak_alex isak.png\n",
            "Saved cropped face to debug_cropped_faces/alisson becker_alisson becker.jpg\n",
            "Saved cropped face to debug_cropped_faces/arne slot_arne slot.jpeg\n",
            "Saved cropped face to debug_cropped_faces/arne slot_arne slot.jpg\n",
            "Saved cropped face to debug_cropped_faces/ben sesko_ben sesko.png\n",
            "Saved cropped face to debug_cropped_faces/cody gakpo_cody gakpo.png\n",
            "Saved cropped face to debug_cropped_faces/cole palmer_cole palmer.png\n",
            "Saved cropped face to debug_cropped_faces/diogo jota_diogo jota.jpg\n",
            "Saved cropped face to debug_cropped_faces/dom szoboszlai_dom szoboszlai.png\n",
            "Saved cropped face to debug_cropped_faces/erling haaland_erling haaland.jpg\n",
            "Saved cropped face to debug_cropped_faces/fred chiesa_fred chiesa.jpg\n",
            "Saved cropped face to debug_cropped_faces/luis diaz_luis diaz.jpg\n",
            "Saved cropped face to debug_cropped_faces/mo salah_mo salah.jpg\n",
            "Saved cropped face to debug_cropped_faces/moh salah_moh salah.jpeg\n",
            "Saved cropped face to debug_cropped_faces/moh salah_moh salah.png\n",
            "Saved cropped face to debug_cropped_faces/vvd_vvd.jpeg\n",
            "Saved cropped face to debug_cropped_faces/vvd_vvd.jpg\n",
            "Enrolling: alewx arnold -> d854044e-c401-4dd9-bfd2-797887cc3af6\n",
            "Enrolling: alex isak -> 4b414e3a-3230-42d3-9683-c69be2eac7a6\n",
            "Enrolling: alisson becker -> 1d3a112e-305f-4401-839d-9f2b07df1453\n",
            "Enrolling: arne slot -> eb56aa63-e531-4129-97b6-6c6c1fc3318a\n",
            "Enrolling: ben sesko -> ba09be8f-8b70-44f8-a86d-2ed5be8ea740\n",
            "Enrolling: cody gakpo -> 3f1e875b-18e1-41ec-b82b-640820ae5332\n",
            "Enrolling: cole palmer -> ce46053e-148d-4012-bf6c-86142dd04886\n",
            "Enrolling: diogo jota -> 361a2512-1db7-4aa0-b1a9-ae306abf87f8\n",
            "Enrolling: dom szoboszlai -> 64e11354-aad2-44f4-ae65-0d1e6da033f7\n",
            "Enrolling: erling haaland -> 211d9749-206a-448c-88a6-a00814ddff6c\n",
            "Enrolling: fred chiesa -> 61ea9b11-0f4c-4ba9-acf5-2ee6476bda2b\n",
            "Enrolling: luis diaz -> 75fe03d6-5756-42af-8d0d-4b5ebb739217\n",
            "Enrolling: mo salah -> 4222eabf-bbb6-4f94-b125-d8ef61eafb6c\n",
            "Enrolling: moh salah -> e7bb5912-1fb4-40de-ba31-e89ef89f4374\n",
            "Enrolling: vvd -> 23805529-7d82-4466-b2b0-cea836fcbab4\n",
            "Enrollment done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show collection info and scroll 5 points\n",
        "info = qdrant_client.get_collection(\"First\")\n",
        "print(\"Points count on server:\", info.points_count)\n",
        "# Corrected scroll command to access points from the tuple\n",
        "resp, _ = qdrant_client.scroll(collection_name=\"First\", limit=5)\n",
        "for p in resp:\n",
        "    print(\"id:\", p.id, \"payload:\", p.payload)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BHcEoazRQcL",
        "outputId": "166ef8c5-1574-401f-8b84-1c0893872548"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Points count on server: 33\n",
            "id: 1 payload: {'user_id': 'd854044e-c401-4dd9-bfd2-797887cc3af6', 'user_name': 'alewx arnold', 'source_image': '/content/drive/MyDrive/Face Detection System/Liverpool Players/alewx arnold.png', 'type': 'face'}\n",
            "id: 2 payload: {'user_id': 'd854044e-c401-4dd9-bfd2-797887cc3af6', 'user_name': 'alewx arnold', 'type': 'centroid'}\n",
            "id: 3 payload: {'user_id': '4b414e3a-3230-42d3-9683-c69be2eac7a6', 'user_name': 'alex isak', 'source_image': '/content/drive/MyDrive/Face Detection System/Liverpool Players/alex isak.png', 'type': 'face'}\n",
            "id: 4 payload: {'user_id': '4b414e3a-3230-42d3-9683-c69be2eac7a6', 'user_name': 'alex isak', 'type': 'centroid'}\n",
            "id: 5 payload: {'user_id': '1d3a112e-305f-4401-839d-9f2b07df1453', 'user_name': 'alisson becker', 'source_image': '/content/drive/MyDrive/Face Detection System/Liverpool Players/alisson becker.jpg', 'type': 'face'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FAISS fallback class (same idea)\n",
        "class FaissIndexFallback:\n",
        "    def __init__(self, dim=VECTOR_SIZE):\n",
        "        if not FAISS_AVAILABLE:\n",
        "            raise RuntimeError(\"faiss not available\")\n",
        "        self.dim = dim\n",
        "        self.ids = []\n",
        "        self.index = faiss.IndexFlatIP(dim)\n",
        "    def add(self, vec: np.ndarray, id_str: str):\n",
        "        v = vec.astype('float32').reshape(1,-1)\n",
        "        self.index.add(v)\n",
        "        self.ids.append(id_str)\n",
        "    def search(self, vec: np.ndarray, top_k=1):\n",
        "        q = vec.astype('float32').reshape(1,-1)\n",
        "        D, I = self.index.search(q, top_k)\n",
        "        out = []\n",
        "        for score, idx in zip(D[0], I[0]):\n",
        "            if idx == -1:\n",
        "                continue\n",
        "            out.append((self.ids[idx], float(score), None))\n",
        "        return out\n",
        "\n",
        "faiss_index = None\n",
        "if not use_qdrant and FAISS_AVAILABLE:\n",
        "    faiss_index = FaissIndexFallback(dim=VECTOR_SIZE)\n",
        "    print(\"FAISS fallback ready\")"
      ],
      "metadata": {
        "id": "F6y4zJYZoEc3"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DeepSort initialization (replaces SimpleTracker)\n",
        "if not DEEPSORT_AVAILABLE:\n",
        "    raise RuntimeError(\"deep_sort_realtime is required. Install with `pip install deep_sort_realtime`\")\n",
        "\n",
        "# Create a DeepSort tracker instance.\n",
        "# Tune max_age, n_init, and nn_budget as needed for your scenario.\n",
        "deepsort = DeepSort(max_age=30, n_init=3, nms_max_overlap=1.0, max_cosine_distance=0.4, nn_budget=100)\n",
        "\n",
        "# We'll maintain our own per-track metadata (last_embedding, last_match, last_frame)\n",
        "track_store = {}  # track_id -> {last_embedding, last_match, last_frame}"
      ],
      "metadata": {
        "id": "TvinytdmoKnv"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Qdrant / FAISS search helpers\n",
        "def qdrant_search(emb: np.ndarray, q_client: QdrantClient, collection_name: str, top_k=1):\n",
        "    res = q_client.search(collection_name=collection_name, query_vector=emb.tolist(), limit=top_k)\n",
        "    out = []\n",
        "    for r in res:\n",
        "        out.append((str(r.id), float(r.score), r.payload))\n",
        "    return out\n",
        "\n",
        "def faiss_search(emb: np.ndarray, idx: FaissIndexFallback, top_k=1):\n",
        "    return idx.search(emb, top_k)"
      ],
      "metadata": {
        "id": "aa52VeS3oPqI"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Video processing loop using DeepSort\n",
        "def process_video_with_deepsort(video_path: str, output_path: str = None, camera_id: str = \"cam-1\",\n",
        "                               q_client: QdrantClient = qdrant_client, collection_name: str = COLLECTION_NAME,\n",
        "                               frame_skip: int = FRAME_SKIP, embed_every_n: int = EMBED_EVERY_N_FRAMES,\n",
        "                               match_threshold: float = MATCH_THRESHOLD):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(\"Cannot open video: \" + str(video_path))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 25.0\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    writer = None\n",
        "    if output_path:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "        writer = cv2.VideoWriter(output_path, fourcc, fps / frame_skip, (width, height))\n",
        "\n",
        "    frame_idx = 0\n",
        "    saved_events = 0\n",
        "\n",
        "    while True:\n",
        "        ok, frame = cap.read()\n",
        "        if not ok:\n",
        "            break\n",
        "        frame_idx += 1\n",
        "        if frame_idx % frame_skip != 0:\n",
        "            if writer:\n",
        "                writer.write(frame)\n",
        "            continue\n",
        "\n",
        "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        pil = Image.fromarray(rgb)\n",
        "\n",
        "        # detect faces (keep_all True so returns all faces)\n",
        "        # convert BGR->RGB for YOLO (recommended)\n",
        "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Run YOLO on current frame (img_rgb is frame in RGB)\n",
        "        results = yolo_model(img_rgb, imgsz=640)[0]\n",
        "\n",
        "        # boxes: results.boxes.xyxy  (tensor) ; conf: results.boxes.conf ; cls: results.boxes.cls\n",
        "        dets_for_tracker = []\n",
        "        if results and getattr(results, \"boxes\", None) is not None:\n",
        "            xyxy = results.boxes.xyxy.cpu().numpy()   # shape (N,4): x1,y1,x2,y2\n",
        "            confs = results.boxes.conf.cpu().numpy()  # shape (N,)\n",
        "            for (x1, y1, x2, y2), conf in zip(xyxy, confs):\n",
        "                if conf < 0.30:\n",
        "                    continue\n",
        "                # clamp to frame boundaries and convert to int\n",
        "                x1 = int(max(0, min(x1, width-1)))\n",
        "                y1 = int(max(0, min(y1, height-1)))\n",
        "                x2 = int(max(0, min(x2, width-1)))\n",
        "                y2 = int(max(0, min(y2, height-1)))\n",
        "                # deep_sort expects: (bbox_tlbr, confidence, class_id_or_label)\n",
        "                dets_for_tracker.append(([x1, y1, x2, y2], float(conf), \"face\"))\n",
        "\n",
        "\n",
        "        # update deep sort with the correct detection format\n",
        "        tracks = deepsort.update_tracks(dets_for_tracker, frame=frame)\n",
        "\n",
        "        # Iterate tracks — use tr.to_tlbr() which should return [x1,y1,x2,y2]\n",
        "        for tr in tracks:\n",
        "            if not tr.is_confirmed():\n",
        "                continue\n",
        "            track_id = str(tr.track_id)\n",
        "            tlbr = tr.to_tlbr()  # expected [x1,y1,x2,y2]\n",
        "            # make sure tlbr is iterable with four numbers\n",
        "            if isinstance(tlbr, (list, tuple, np.ndarray)) and len(tlbr) >= 4:\n",
        "                x1, y1, x2, y2 = int(tlbr[0]), int(tlbr[1]), int(tlbr[2]), int(tlbr[3])\n",
        "            else:\n",
        "                # fallback: try attr order alternatives (rare)\n",
        "                arr = list(tlbr)\n",
        "                x1, y1, x2, y2 = int(arr[0]), int(arr[1]), int(arr[2]), int(arr[3])\n",
        "\n",
        "            # clamp (safety)\n",
        "            x1 = max(0, min(width-1, x1))\n",
        "            y1 = max(0, min(height-1, y1))\n",
        "            x2 = max(0, min(width-1, x2))\n",
        "            y2 = max(0, min(height-1, y2))\n",
        "\n",
        "            # decide whether to compute embedding now (throttle)\n",
        "            store = track_store.get(track_id, {\"last_embedding\": None, \"last_match\": None, \"last_frame\": -999})\n",
        "            compute = False\n",
        "            if store[\"last_embedding\"] is None:\n",
        "                compute = True\n",
        "            elif (frame_idx - store[\"last_frame\"]) >= embed_every_n:\n",
        "                compute = True\n",
        "\n",
        "            name = None; score = None; decision = \"unknown\"; user_id = None\n",
        "\n",
        "            if compute:\n",
        "                face_pil = Image.fromarray(rgb).crop((x1,y1,x2,y2)).resize((160,160))\n",
        "                emb = get_embedding_from_pil(face_pil)\n",
        "\n",
        "                if use_qdrant and q_client is not None:\n",
        "                    res = qdrant_search(emb, q_client, collection_name=collection_name, top_k=1)\n",
        "                elif faiss_index is not None:\n",
        "                    res = faiss_search(emb, faiss_index, top_k=1)\n",
        "                else:\n",
        "                    res = []\n",
        "\n",
        "                if res:\n",
        "                    pid, sc, payload = res[0]\n",
        "                    score = sc\n",
        "                    if score >= match_threshold:\n",
        "                        if payload:\n",
        "                            user_id = payload.get(\"user_id\") or pid\n",
        "                            name = payload.get(\"user_name\") or user_id\n",
        "                        else:\n",
        "                            cur = meta_conn.cursor()\n",
        "                            cur.execute(\"SELECT name FROM users WHERE user_id=?\", (pid,))\n",
        "                            r = cur.fetchone()\n",
        "                            name = r[0] if r else pid\n",
        "                            user_id = pid\n",
        "                        decision = \"allow\"\n",
        "                    else:\n",
        "                        decision = \"unknown\"\n",
        "                else:\n",
        "                    decision = \"unknown\"\n",
        "\n",
        "                # update store\n",
        "                store[\"last_embedding\"] = emb\n",
        "                store[\"last_match\"] = {\"decision\": decision, \"name\": name, \"score\": float(score) if score is not None else None}\n",
        "                store[\"last_frame\"] = frame_idx\n",
        "                track_store[track_id] = store\n",
        "            else:\n",
        "                lastm = store.get(\"last_match\")\n",
        "                if lastm:\n",
        "                    decision = lastm.get(\"decision\", \"unknown\")\n",
        "                    name = lastm.get(\"name\")\n",
        "                    score = lastm.get(\"score\")\n",
        "\n",
        "            # draw bounding box and label\n",
        "            color = (0,255,0) if decision == \"allow\" else (0,0,255)\n",
        "            label = f\"{name or 'Unknown'} {score:.3f}\" if score is not None else (name or \"Unknown\")\n",
        "            cv2.rectangle(frame, (x1,y1), (x2,y2), color, 3)\n",
        "            cv2.putText(frame, label, (x1, max(15, y1-6)), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
        "\n",
        "            # snapshot & log\n",
        "            if decision in (\"allow\", \"unknown\"):\n",
        "                snapshot_path = f\"{SNAPSHOT_DIR}/{camera_id}_{track_id}_{int(time.time())}.jpg\"\n",
        "                cv2.imwrite(snapshot_path, frame[y1:y2, x1:x2])\n",
        "                cur = meta_conn.cursor()\n",
        "                log_id = str(uuid.uuid4())\n",
        "                cur.execute(\"INSERT INTO access_logs (log_id, camera_id, user_id, match_score, decision, snapshot_path, extra) VALUES (?,?,?,?,?,?,?)\",\n",
        "                            (log_id, camera_id, user_id if decision==\"allow\" else None, float(score) if score is not None else None, decision, snapshot_path, json.dumps({\"frame_idx\": frame_idx, \"track_id\": track_id})))\n",
        "                meta_conn.commit()\n",
        "                saved_events += 1\n",
        "\n",
        "        # write frame to output\n",
        "        if writer:\n",
        "            writer.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    if writer:\n",
        "        writer.release()\n",
        "    print(\"Video processed. events saved:\", saved_events)"
      ],
      "metadata": {
        "id": "i4SSs6O7obJh"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Loaded DeepSORT pipeline. Use enroll_from_folder(...) then process_video_with_deepsort(...)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6d7kwUepAdQ",
        "outputId": "5832c8b4-591f-4936-a5e5-641675daea89"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded DeepSORT pipeline. Use enroll_from_folder(...) then process_video_with_deepsort(...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16ec7cdd",
        "outputId": "70ca2c99-d99b-473b-aa89-2fdd735cd907"
      },
      "source": [
        "# Run the enrollment process\n",
        "enroll_from_folder()\n",
        "\n",
        "# Define the path to your test video\n",
        "test_video_path = \"/content/drive/MyDrive/Face Detection System/Test Video/Liverpool Player Squad Name.mp4\"\n",
        "\n",
        "# Define the output path for the processed video\n",
        "output_video_path = \"/content/drive/MyDrive/Face Detection System/Test Video/Liverpool_Player_Squad_Name_processed.mp4\"\n",
        "\n",
        "# Process the test video\n",
        "process_video_with_deepsort(video_path=test_video_path, output_path=output_video_path)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-112905981.py:24: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant_client.recreate_collection(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'First' recreated.\n",
            "Cleared existing data in SQLite database.\n",
            "Saved cropped face to debug_cropped_faces/alewx arnold_alewx arnold.png\n",
            "Saved cropped face to debug_cropped_faces/alex isak_alex isak.png\n",
            "Saved cropped face to debug_cropped_faces/alisson becker_alisson becker.jpg\n",
            "Saved cropped face to debug_cropped_faces/arne slot_arne slot.jpeg\n",
            "Saved cropped face to debug_cropped_faces/arne slot_arne slot.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved cropped face to debug_cropped_faces/ben sesko_ben sesko.png\n",
            "Saved cropped face to debug_cropped_faces/cody gakpo_cody gakpo.png\n",
            "Saved cropped face to debug_cropped_faces/cole palmer_cole palmer.png\n",
            "Saved cropped face to debug_cropped_faces/diogo jota_diogo jota.jpg\n",
            "Saved cropped face to debug_cropped_faces/dom szoboszlai_dom szoboszlai.png\n",
            "Saved cropped face to debug_cropped_faces/erling haaland_erling haaland.jpg\n",
            "Saved cropped face to debug_cropped_faces/fred chiesa_fred chiesa.jpg\n",
            "Saved cropped face to debug_cropped_faces/luis diaz_luis diaz.jpg\n",
            "Saved cropped face to debug_cropped_faces/mo salah_mo salah.jpg\n",
            "Saved cropped face to debug_cropped_faces/moh salah_moh salah.jpeg\n",
            "Saved cropped face to debug_cropped_faces/moh salah_moh salah.png\n",
            "Saved cropped face to debug_cropped_faces/vvd_vvd.jpeg\n",
            "Saved cropped face to debug_cropped_faces/vvd_vvd.jpg\n",
            "Enrolling: alewx arnold -> c2a4365b-b35a-41b4-8eb3-8bbdadbf6dc7\n",
            "Enrolling: alex isak -> 7345be2d-33a5-4d2b-a825-f3bb2749e9c1\n",
            "Enrolling: alisson becker -> 02c4e080-7af0-460c-a34d-addcd714fd57\n",
            "Enrolling: arne slot -> b457dffa-82d3-4f32-a136-8f734736a7f1\n",
            "Enrolling: ben sesko -> d940a25f-3c1a-498d-a166-4cf4551c6d5d\n",
            "Enrolling: cody gakpo -> 36f2d869-e3f9-4b69-88ca-ccdc14d53c4b\n",
            "Enrolling: cole palmer -> 575784c0-da3f-4eeb-b0cf-a4a5eda10c87\n",
            "Enrolling: diogo jota -> e68ecce5-2ca4-4ccb-ade4-7939e33f900c\n",
            "Enrolling: dom szoboszlai -> 5281ad90-8b8d-40b0-a7e0-d37cddb0b42d\n",
            "Enrolling: erling haaland -> 698898e3-5ad9-469e-9e91-6b7eac87e4ee\n",
            "Enrolling: fred chiesa -> 501c4934-125e-4401-85bf-17518fbf45c4\n",
            "Enrolling: luis diaz -> bbe44da6-9d0b-45ae-a2ee-18bf60581d93\n",
            "Enrolling: mo salah -> 0d354d5a-a9ec-4926-ab32-4f9825a3add4\n",
            "Enrolling: moh salah -> 329a6cc3-f428-48ec-837b-b47c7c3262be\n",
            "Enrolling: vvd -> 29b9bdac-d52b-42eb-8728-089d6401b0e8\n",
            "Enrollment done.\n",
            "\n",
            "0: 640x384 1 face, 125.1ms\n",
            "Speed: 4.8ms preprocess, 125.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 145.9ms\n",
            "Speed: 4.3ms preprocess, 145.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 127.5ms\n",
            "Speed: 3.8ms preprocess, 127.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3938043720.py:3: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  res = q_client.search(collection_name=collection_name, query_vector=emb.tolist(), limit=top_k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 640x384 1 face, 125.4ms\n",
            "Speed: 4.7ms preprocess, 125.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 117.4ms\n",
            "Speed: 3.5ms preprocess, 117.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 131.0ms\n",
            "Speed: 4.4ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 124.8ms\n",
            "Speed: 3.7ms preprocess, 124.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 125.1ms\n",
            "Speed: 3.5ms preprocess, 125.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 140.7ms\n",
            "Speed: 3.5ms preprocess, 140.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.3ms\n",
            "Speed: 7.0ms preprocess, 138.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.6ms\n",
            "Speed: 3.2ms preprocess, 138.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.5ms\n",
            "Speed: 3.4ms preprocess, 119.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 154.2ms\n",
            "Speed: 5.4ms preprocess, 154.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.8ms\n",
            "Speed: 3.8ms preprocess, 137.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.7ms\n",
            "Speed: 7.5ms preprocess, 139.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 200.3ms\n",
            "Speed: 4.5ms preprocess, 200.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 186.8ms\n",
            "Speed: 7.4ms preprocess, 186.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 193.5ms\n",
            "Speed: 8.9ms preprocess, 193.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 227.3ms\n",
            "Speed: 5.1ms preprocess, 227.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 185.3ms\n",
            "Speed: 3.4ms preprocess, 185.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 212.7ms\n",
            "Speed: 3.5ms preprocess, 212.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 205.4ms\n",
            "Speed: 10.4ms preprocess, 205.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 195.3ms\n",
            "Speed: 3.4ms preprocess, 195.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 212.0ms\n",
            "Speed: 3.4ms preprocess, 212.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 121.2ms\n",
            "Speed: 5.5ms preprocess, 121.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.2ms\n",
            "Speed: 3.9ms preprocess, 137.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 148.8ms\n",
            "Speed: 6.3ms preprocess, 148.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 117.3ms\n",
            "Speed: 4.6ms preprocess, 117.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.2ms\n",
            "Speed: 3.8ms preprocess, 138.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.5ms\n",
            "Speed: 3.6ms preprocess, 135.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.1ms\n",
            "Speed: 3.3ms preprocess, 135.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 120.6ms\n",
            "Speed: 3.9ms preprocess, 120.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.3ms\n",
            "Speed: 6.9ms preprocess, 132.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 160.5ms\n",
            "Speed: 5.2ms preprocess, 160.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 147.5ms\n",
            "Speed: 3.9ms preprocess, 147.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 122.9ms\n",
            "Speed: 4.0ms preprocess, 122.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 150.6ms\n",
            "Speed: 3.3ms preprocess, 150.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.0ms\n",
            "Speed: 4.5ms preprocess, 137.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.7ms\n",
            "Speed: 4.0ms preprocess, 135.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 114.2ms\n",
            "Speed: 4.0ms preprocess, 114.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 133.9ms\n",
            "Speed: 3.7ms preprocess, 133.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.0ms\n",
            "Speed: 6.1ms preprocess, 137.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.3ms\n",
            "Speed: 4.5ms preprocess, 142.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.2ms\n",
            "Speed: 3.8ms preprocess, 132.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.8ms\n",
            "Speed: 3.9ms preprocess, 135.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.2ms\n",
            "Speed: 4.4ms preprocess, 136.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.8ms\n",
            "Speed: 4.2ms preprocess, 135.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 117.7ms\n",
            "Speed: 3.3ms preprocess, 117.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.8ms\n",
            "Speed: 3.3ms preprocess, 139.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.3ms\n",
            "Speed: 3.3ms preprocess, 137.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.7ms\n",
            "Speed: 6.1ms preprocess, 138.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.2ms\n",
            "Speed: 4.7ms preprocess, 119.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.3ms\n",
            "Speed: 3.7ms preprocess, 137.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 131.9ms\n",
            "Speed: 6.0ms preprocess, 131.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 152.1ms\n",
            "Speed: 6.4ms preprocess, 152.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 120.2ms\n",
            "Speed: 3.8ms preprocess, 120.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.9ms\n",
            "Speed: 3.7ms preprocess, 138.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 155.7ms\n",
            "Speed: 6.0ms preprocess, 155.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 194.0ms\n",
            "Speed: 3.5ms preprocess, 194.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 183.7ms\n",
            "Speed: 3.3ms preprocess, 183.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 190.5ms\n",
            "Speed: 11.1ms preprocess, 190.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 185.8ms\n",
            "Speed: 6.5ms preprocess, 185.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 192.3ms\n",
            "Speed: 8.9ms preprocess, 192.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 191.6ms\n",
            "Speed: 4.9ms preprocess, 191.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 212.5ms\n",
            "Speed: 5.9ms preprocess, 212.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 213.0ms\n",
            "Speed: 4.0ms preprocess, 213.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 203.5ms\n",
            "Speed: 4.6ms preprocess, 203.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 161.2ms\n",
            "Speed: 3.3ms preprocess, 161.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.0ms\n",
            "Speed: 5.9ms preprocess, 138.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.9ms\n",
            "Speed: 4.2ms preprocess, 136.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.2ms\n",
            "Speed: 4.4ms preprocess, 137.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 115.2ms\n",
            "Speed: 3.6ms preprocess, 115.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.0ms\n",
            "Speed: 5.3ms preprocess, 136.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 133.8ms\n",
            "Speed: 6.9ms preprocess, 133.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.7ms\n",
            "Speed: 6.9ms preprocess, 132.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.0ms\n",
            "Speed: 4.6ms preprocess, 119.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.8ms\n",
            "Speed: 5.0ms preprocess, 132.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.0ms\n",
            "Speed: 3.9ms preprocess, 135.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 156.7ms\n",
            "Speed: 3.3ms preprocess, 156.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.7ms\n",
            "Speed: 4.5ms preprocess, 119.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.8ms\n",
            "Speed: 6.2ms preprocess, 138.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 144.6ms\n",
            "Speed: 5.2ms preprocess, 144.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.2ms\n",
            "Speed: 6.6ms preprocess, 135.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 122.2ms\n",
            "Speed: 3.8ms preprocess, 122.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.2ms\n",
            "Speed: 7.0ms preprocess, 139.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.3ms\n",
            "Speed: 5.8ms preprocess, 142.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.3ms\n",
            "Speed: 5.0ms preprocess, 137.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 115.1ms\n",
            "Speed: 4.5ms preprocess, 115.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.4ms\n",
            "Speed: 4.1ms preprocess, 141.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.0ms\n",
            "Speed: 3.4ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.5ms\n",
            "Speed: 3.3ms preprocess, 142.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 120.1ms\n",
            "Speed: 4.2ms preprocess, 120.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 133.7ms\n",
            "Speed: 4.6ms preprocess, 133.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.3ms\n",
            "Speed: 5.1ms preprocess, 135.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.9ms\n",
            "Speed: 3.4ms preprocess, 141.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 130.6ms\n",
            "Speed: 3.8ms preprocess, 130.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.4ms\n",
            "Speed: 7.1ms preprocess, 139.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 140.5ms\n",
            "Speed: 3.5ms preprocess, 140.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 133.4ms\n",
            "Speed: 9.6ms preprocess, 133.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 117.3ms\n",
            "Speed: 4.2ms preprocess, 117.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 150.4ms\n",
            "Speed: 3.8ms preprocess, 150.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 198.6ms\n",
            "Speed: 3.7ms preprocess, 198.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 204.6ms\n",
            "Speed: 6.6ms preprocess, 204.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 186.7ms\n",
            "Speed: 3.7ms preprocess, 186.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 202.1ms\n",
            "Speed: 3.4ms preprocess, 202.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 183.3ms\n",
            "Speed: 3.4ms preprocess, 183.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 192.8ms\n",
            "Speed: 3.3ms preprocess, 192.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 187.0ms\n",
            "Speed: 4.0ms preprocess, 187.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 198.7ms\n",
            "Speed: 4.7ms preprocess, 198.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 206.9ms\n",
            "Speed: 5.6ms preprocess, 206.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 193.0ms\n",
            "Speed: 9.4ms preprocess, 193.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 121.3ms\n",
            "Speed: 3.9ms preprocess, 121.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 156.2ms\n",
            "Speed: 3.6ms preprocess, 156.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.6ms\n",
            "Speed: 3.4ms preprocess, 136.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.5ms\n",
            "Speed: 3.3ms preprocess, 135.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 124.0ms\n",
            "Speed: 3.8ms preprocess, 124.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 129.8ms\n",
            "Speed: 5.2ms preprocess, 129.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 131.9ms\n",
            "Speed: 4.9ms preprocess, 131.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.4ms\n",
            "Speed: 6.6ms preprocess, 138.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.5ms\n",
            "Speed: 3.5ms preprocess, 136.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 143.2ms\n",
            "Speed: 3.4ms preprocess, 143.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 143.5ms\n",
            "Speed: 3.5ms preprocess, 143.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.8ms\n",
            "Speed: 5.4ms preprocess, 138.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 131.1ms\n",
            "Speed: 4.5ms preprocess, 131.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.3ms\n",
            "Speed: 4.3ms preprocess, 137.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.9ms\n",
            "Speed: 7.1ms preprocess, 136.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 151.0ms\n",
            "Speed: 7.9ms preprocess, 151.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.8ms\n",
            "Speed: 3.6ms preprocess, 119.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 140.7ms\n",
            "Speed: 4.6ms preprocess, 140.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.2ms\n",
            "Speed: 4.5ms preprocess, 136.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.2ms\n",
            "Speed: 4.4ms preprocess, 137.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 115.8ms\n",
            "Speed: 4.5ms preprocess, 115.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.2ms\n",
            "Speed: 3.6ms preprocess, 137.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 146.2ms\n",
            "Speed: 3.5ms preprocess, 146.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.8ms\n",
            "Speed: 3.7ms preprocess, 138.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 118.2ms\n",
            "Speed: 4.6ms preprocess, 118.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.2ms\n",
            "Speed: 3.6ms preprocess, 138.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 131.3ms\n",
            "Speed: 3.3ms preprocess, 131.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.5ms\n",
            "Speed: 3.9ms preprocess, 132.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 120.6ms\n",
            "Speed: 3.6ms preprocess, 120.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 143.7ms\n",
            "Speed: 3.4ms preprocess, 143.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 140.7ms\n",
            "Speed: 6.7ms preprocess, 140.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.1ms\n",
            "Speed: 7.2ms preprocess, 142.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 212.2ms\n",
            "Speed: 3.5ms preprocess, 212.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 224.8ms\n",
            "Speed: 4.2ms preprocess, 224.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 195.0ms\n",
            "Speed: 6.0ms preprocess, 195.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 187.6ms\n",
            "Speed: 9.1ms preprocess, 187.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 187.3ms\n",
            "Speed: 6.1ms preprocess, 187.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 214.3ms\n",
            "Speed: 6.1ms preprocess, 214.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 192.4ms\n",
            "Speed: 3.3ms preprocess, 192.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 209.5ms\n",
            "Speed: 3.6ms preprocess, 209.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 188.9ms\n",
            "Speed: 3.6ms preprocess, 188.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 209.3ms\n",
            "Speed: 5.8ms preprocess, 209.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.9ms\n",
            "Speed: 3.4ms preprocess, 137.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.1ms\n",
            "Speed: 7.0ms preprocess, 139.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 113.9ms\n",
            "Speed: 3.3ms preprocess, 113.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 153.1ms\n",
            "Speed: 4.1ms preprocess, 153.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 145.5ms\n",
            "Speed: 14.5ms preprocess, 145.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.0ms\n",
            "Speed: 4.5ms preprocess, 135.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.4ms\n",
            "Speed: 3.7ms preprocess, 119.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.4ms\n",
            "Speed: 3.9ms preprocess, 138.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 146.0ms\n",
            "Speed: 7.6ms preprocess, 146.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.7ms\n",
            "Speed: 4.4ms preprocess, 138.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.7ms\n",
            "Speed: 3.5ms preprocess, 119.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 153.6ms\n",
            "Speed: 3.8ms preprocess, 153.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.1ms\n",
            "Speed: 6.5ms preprocess, 134.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.4ms\n",
            "Speed: 7.2ms preprocess, 137.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 120.4ms\n",
            "Speed: 4.6ms preprocess, 120.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.4ms\n",
            "Speed: 4.5ms preprocess, 136.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.2ms\n",
            "Speed: 10.1ms preprocess, 137.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 143.6ms\n",
            "Speed: 4.9ms preprocess, 143.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 125.1ms\n",
            "Speed: 5.0ms preprocess, 125.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 133.9ms\n",
            "Speed: 3.5ms preprocess, 133.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.6ms\n",
            "Speed: 3.6ms preprocess, 139.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 140.5ms\n",
            "Speed: 3.7ms preprocess, 140.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 120.3ms\n",
            "Speed: 3.7ms preprocess, 120.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.3ms\n",
            "Speed: 7.7ms preprocess, 141.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.2ms\n",
            "Speed: 6.6ms preprocess, 141.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 154.6ms\n",
            "Speed: 5.7ms preprocess, 154.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 118.0ms\n",
            "Speed: 3.3ms preprocess, 118.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.7ms\n",
            "Speed: 3.4ms preprocess, 139.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.6ms\n",
            "Speed: 3.4ms preprocess, 134.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.5ms\n",
            "Speed: 4.3ms preprocess, 138.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 126.7ms\n",
            "Speed: 6.5ms preprocess, 126.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.9ms\n",
            "Speed: 3.7ms preprocess, 132.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.0ms\n",
            "Speed: 4.0ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 220.0ms\n",
            "Speed: 3.6ms preprocess, 220.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 190.6ms\n",
            "Speed: 3.8ms preprocess, 190.6ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 206.4ms\n",
            "Speed: 4.1ms preprocess, 206.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 192.0ms\n",
            "Speed: 8.2ms preprocess, 192.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 183.4ms\n",
            "Speed: 4.4ms preprocess, 183.4ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 179.9ms\n",
            "Speed: 3.7ms preprocess, 179.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 189.2ms\n",
            "Speed: 4.4ms preprocess, 189.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 207.9ms\n",
            "Speed: 6.0ms preprocess, 207.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 204.4ms\n",
            "Speed: 3.8ms preprocess, 204.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 217.1ms\n",
            "Speed: 3.8ms preprocess, 217.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.5ms\n",
            "Speed: 4.1ms preprocess, 141.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.7ms\n",
            "Speed: 7.2ms preprocess, 136.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.8ms\n",
            "Speed: 4.4ms preprocess, 136.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 117.8ms\n",
            "Speed: 3.8ms preprocess, 117.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.3ms\n",
            "Speed: 3.5ms preprocess, 137.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.7ms\n",
            "Speed: 3.5ms preprocess, 139.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.2ms\n",
            "Speed: 3.5ms preprocess, 139.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 115.4ms\n",
            "Speed: 4.4ms preprocess, 115.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 133.7ms\n",
            "Speed: 3.7ms preprocess, 133.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.2ms\n",
            "Speed: 3.6ms preprocess, 134.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.7ms\n",
            "Speed: 3.5ms preprocess, 132.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 117.0ms\n",
            "Speed: 3.6ms preprocess, 117.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.6ms\n",
            "Speed: 3.7ms preprocess, 136.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 154.2ms\n",
            "Speed: 3.6ms preprocess, 154.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.0ms\n",
            "Speed: 6.3ms preprocess, 135.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 116.6ms\n",
            "Speed: 4.7ms preprocess, 116.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 140.1ms\n",
            "Speed: 3.5ms preprocess, 140.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 127.3ms\n",
            "Speed: 4.2ms preprocess, 127.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.7ms\n",
            "Speed: 4.2ms preprocess, 135.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 123.4ms\n",
            "Speed: 3.7ms preprocess, 123.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 151.7ms\n",
            "Speed: 4.6ms preprocess, 151.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.7ms\n",
            "Speed: 3.6ms preprocess, 134.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.7ms\n",
            "Speed: 3.5ms preprocess, 134.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 121.2ms\n",
            "Speed: 3.5ms preprocess, 121.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 129.7ms\n",
            "Speed: 5.1ms preprocess, 129.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 145.4ms\n",
            "Speed: 8.1ms preprocess, 145.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.2ms\n",
            "Speed: 4.0ms preprocess, 141.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 116.5ms\n",
            "Speed: 3.5ms preprocess, 116.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.7ms\n",
            "Speed: 3.2ms preprocess, 134.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 133.0ms\n",
            "Speed: 7.1ms preprocess, 133.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.9ms\n",
            "Speed: 3.4ms preprocess, 136.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 120.6ms\n",
            "Speed: 4.5ms preprocess, 120.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.9ms\n",
            "Speed: 3.6ms preprocess, 136.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 216.4ms\n",
            "Speed: 4.7ms preprocess, 216.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 193.3ms\n",
            "Speed: 3.3ms preprocess, 193.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 185.3ms\n",
            "Speed: 3.3ms preprocess, 185.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 189.0ms\n",
            "Speed: 5.3ms preprocess, 189.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 189.4ms\n",
            "Speed: 7.5ms preprocess, 189.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 185.5ms\n",
            "Speed: 7.6ms preprocess, 185.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 199.6ms\n",
            "Speed: 3.7ms preprocess, 199.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 199.2ms\n",
            "Speed: 9.8ms preprocess, 199.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 223.7ms\n",
            "Speed: 3.3ms preprocess, 223.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 198.7ms\n",
            "Speed: 6.9ms preprocess, 198.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.0ms\n",
            "Speed: 4.2ms preprocess, 119.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.9ms\n",
            "Speed: 7.0ms preprocess, 136.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 147.1ms\n",
            "Speed: 5.5ms preprocess, 147.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.4ms\n",
            "Speed: 4.8ms preprocess, 141.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.3ms\n",
            "Speed: 4.6ms preprocess, 132.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.7ms\n",
            "Speed: 4.0ms preprocess, 141.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.7ms\n",
            "Speed: 7.4ms preprocess, 137.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.9ms\n",
            "Speed: 3.8ms preprocess, 137.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.1ms\n",
            "Speed: 4.2ms preprocess, 134.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 140.7ms\n",
            "Speed: 3.3ms preprocess, 140.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.1ms\n",
            "Speed: 5.7ms preprocess, 138.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 155.9ms\n",
            "Speed: 13.5ms preprocess, 155.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 115.0ms\n",
            "Speed: 3.2ms preprocess, 115.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.2ms\n",
            "Speed: 8.8ms preprocess, 142.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.2ms\n",
            "Speed: 4.7ms preprocess, 135.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.7ms\n",
            "Speed: 7.8ms preprocess, 138.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 123.4ms\n",
            "Speed: 3.5ms preprocess, 123.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 537.8ms\n",
            "Speed: 6.3ms preprocess, 537.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 143.6ms\n",
            "Speed: 6.5ms preprocess, 143.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 143.0ms\n",
            "Speed: 7.9ms preprocess, 143.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 124.2ms\n",
            "Speed: 4.9ms preprocess, 124.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.9ms\n",
            "Speed: 3.3ms preprocess, 137.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.8ms\n",
            "Speed: 3.5ms preprocess, 139.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 150.4ms\n",
            "Speed: 8.4ms preprocess, 150.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.6ms\n",
            "Speed: 3.4ms preprocess, 119.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.7ms\n",
            "Speed: 6.8ms preprocess, 141.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 144.6ms\n",
            "Speed: 6.9ms preprocess, 144.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 133.6ms\n",
            "Speed: 4.6ms preprocess, 133.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 118.9ms\n",
            "Speed: 4.0ms preprocess, 118.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.3ms\n",
            "Speed: 3.3ms preprocess, 139.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 174.4ms\n",
            "Speed: 9.1ms preprocess, 174.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 185.7ms\n",
            "Speed: 11.4ms preprocess, 185.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 205.2ms\n",
            "Speed: 3.2ms preprocess, 205.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 178.3ms\n",
            "Speed: 3.4ms preprocess, 178.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 189.3ms\n",
            "Speed: 5.5ms preprocess, 189.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 191.3ms\n",
            "Speed: 5.8ms preprocess, 191.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 195.0ms\n",
            "Speed: 3.4ms preprocess, 195.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 211.8ms\n",
            "Speed: 8.7ms preprocess, 211.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 220.2ms\n",
            "Speed: 3.5ms preprocess, 220.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 201.6ms\n",
            "Speed: 11.6ms preprocess, 201.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 126.3ms\n",
            "Speed: 3.4ms preprocess, 126.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 152.9ms\n",
            "Speed: 4.1ms preprocess, 152.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.3ms\n",
            "Speed: 4.8ms preprocess, 135.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.7ms\n",
            "Speed: 3.8ms preprocess, 136.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 118.9ms\n",
            "Speed: 3.9ms preprocess, 118.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 140.8ms\n",
            "Speed: 9.7ms preprocess, 140.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.5ms\n",
            "Speed: 3.8ms preprocess, 135.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.1ms\n",
            "Speed: 5.6ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 123.1ms\n",
            "Speed: 3.7ms preprocess, 123.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.8ms\n",
            "Speed: 3.6ms preprocess, 139.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 161.4ms\n",
            "Speed: 3.7ms preprocess, 161.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.3ms\n",
            "Speed: 5.1ms preprocess, 136.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.9ms\n",
            "Speed: 5.1ms preprocess, 119.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.3ms\n",
            "Speed: 4.1ms preprocess, 136.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.0ms\n",
            "Speed: 5.1ms preprocess, 135.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.5ms\n",
            "Speed: 3.7ms preprocess, 137.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 117.2ms\n",
            "Speed: 3.4ms preprocess, 117.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 146.0ms\n",
            "Speed: 3.2ms preprocess, 146.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.8ms\n",
            "Speed: 7.3ms preprocess, 141.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 148.4ms\n",
            "Speed: 7.3ms preprocess, 148.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.6ms\n",
            "Speed: 4.9ms preprocess, 141.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.0ms\n",
            "Speed: 4.3ms preprocess, 134.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 131.9ms\n",
            "Speed: 3.8ms preprocess, 131.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.7ms\n",
            "Speed: 3.7ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 122.8ms\n",
            "Speed: 3.8ms preprocess, 122.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.0ms\n",
            "Speed: 5.1ms preprocess, 139.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.0ms\n",
            "Speed: 4.5ms preprocess, 139.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.2ms\n",
            "Speed: 4.5ms preprocess, 138.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 118.5ms\n",
            "Speed: 3.7ms preprocess, 118.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.9ms\n",
            "Speed: 3.5ms preprocess, 134.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 144.4ms\n",
            "Speed: 3.3ms preprocess, 144.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 162.1ms\n",
            "Speed: 3.4ms preprocess, 162.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.4ms\n",
            "Speed: 3.4ms preprocess, 132.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 206.5ms\n",
            "Speed: 5.4ms preprocess, 206.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 186.7ms\n",
            "Speed: 7.1ms preprocess, 186.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 184.4ms\n",
            "Speed: 9.4ms preprocess, 184.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 189.8ms\n",
            "Speed: 3.4ms preprocess, 189.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 195.8ms\n",
            "Speed: 5.4ms preprocess, 195.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 191.8ms\n",
            "Speed: 8.6ms preprocess, 191.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 218.2ms\n",
            "Speed: 6.5ms preprocess, 218.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 191.2ms\n",
            "Speed: 3.4ms preprocess, 191.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 194.3ms\n",
            "Speed: 7.8ms preprocess, 194.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 207.4ms\n",
            "Speed: 5.3ms preprocess, 207.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.2ms\n",
            "Speed: 3.4ms preprocess, 135.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.2ms\n",
            "Speed: 5.2ms preprocess, 141.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.1ms\n",
            "Speed: 3.7ms preprocess, 136.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 150.1ms\n",
            "Speed: 4.0ms preprocess, 150.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.5ms\n",
            "Speed: 3.5ms preprocess, 139.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.5ms\n",
            "Speed: 3.7ms preprocess, 119.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.9ms\n",
            "Speed: 3.4ms preprocess, 138.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.4ms\n",
            "Speed: 3.4ms preprocess, 141.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.4ms\n",
            "Speed: 3.3ms preprocess, 139.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 121.7ms\n",
            "Speed: 5.3ms preprocess, 121.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.1ms\n",
            "Speed: 3.5ms preprocess, 139.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 140.9ms\n",
            "Speed: 4.3ms preprocess, 140.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.9ms\n",
            "Speed: 3.7ms preprocess, 136.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 125.7ms\n",
            "Speed: 3.5ms preprocess, 125.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.5ms\n",
            "Speed: 3.5ms preprocess, 139.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 147.8ms\n",
            "Speed: 3.3ms preprocess, 147.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.8ms\n",
            "Speed: 7.2ms preprocess, 139.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 120.4ms\n",
            "Speed: 4.3ms preprocess, 120.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 147.8ms\n",
            "Speed: 7.4ms preprocess, 147.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.3ms\n",
            "Speed: 4.8ms preprocess, 139.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.5ms\n",
            "Speed: 7.0ms preprocess, 139.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 131.2ms\n",
            "Speed: 4.8ms preprocess, 131.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.2ms\n",
            "Speed: 6.4ms preprocess, 142.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.4ms\n",
            "Speed: 4.9ms preprocess, 142.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.8ms\n",
            "Speed: 4.9ms preprocess, 136.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.3ms\n",
            "Speed: 3.6ms preprocess, 136.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.4ms\n",
            "Speed: 5.4ms preprocess, 138.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 144.5ms\n",
            "Speed: 3.6ms preprocess, 144.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.9ms\n",
            "Speed: 6.0ms preprocess, 137.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 118.9ms\n",
            "Speed: 3.9ms preprocess, 118.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.5ms\n",
            "Speed: 5.3ms preprocess, 139.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.0ms\n",
            "Speed: 5.3ms preprocess, 137.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.7ms\n",
            "Speed: 4.2ms preprocess, 135.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 185.1ms\n",
            "Speed: 3.3ms preprocess, 185.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 204.1ms\n",
            "Speed: 3.4ms preprocess, 204.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 210.5ms\n",
            "Speed: 3.5ms preprocess, 210.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 187.4ms\n",
            "Speed: 6.4ms preprocess, 187.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 195.2ms\n",
            "Speed: 3.5ms preprocess, 195.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 186.0ms\n",
            "Speed: 3.4ms preprocess, 186.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 194.9ms\n",
            "Speed: 5.3ms preprocess, 194.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 214.9ms\n",
            "Speed: 6.1ms preprocess, 214.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 192.7ms\n",
            "Speed: 3.3ms preprocess, 192.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 214.1ms\n",
            "Speed: 4.1ms preprocess, 214.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.7ms\n",
            "Speed: 9.6ms preprocess, 134.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.6ms\n",
            "Speed: 5.0ms preprocess, 138.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.3ms\n",
            "Speed: 3.6ms preprocess, 119.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 158.8ms\n",
            "Speed: 3.7ms preprocess, 158.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.1ms\n",
            "Speed: 8.3ms preprocess, 137.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 143.6ms\n",
            "Speed: 9.9ms preprocess, 143.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.6ms\n",
            "Speed: 2.7ms preprocess, 135.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.9ms\n",
            "Speed: 7.5ms preprocess, 137.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 143.8ms\n",
            "Speed: 3.4ms preprocess, 143.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.9ms\n",
            "Speed: 8.6ms preprocess, 135.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.1ms\n",
            "Speed: 3.8ms preprocess, 119.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.1ms\n",
            "Speed: 8.9ms preprocess, 136.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.3ms\n",
            "Speed: 4.4ms preprocess, 137.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.6ms\n",
            "Speed: 5.2ms preprocess, 138.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 117.0ms\n",
            "Speed: 4.6ms preprocess, 117.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 145.2ms\n",
            "Speed: 3.7ms preprocess, 145.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.1ms\n",
            "Speed: 5.8ms preprocess, 135.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.0ms\n",
            "Speed: 8.0ms preprocess, 141.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 123.7ms\n",
            "Speed: 3.7ms preprocess, 123.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 136.9ms\n",
            "Speed: 7.9ms preprocess, 136.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 145.8ms\n",
            "Speed: 4.3ms preprocess, 145.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.3ms\n",
            "Speed: 4.1ms preprocess, 138.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 129.6ms\n",
            "Speed: 4.5ms preprocess, 129.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.7ms\n",
            "Speed: 4.9ms preprocess, 142.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 130.3ms\n",
            "Speed: 8.8ms preprocess, 130.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 145.6ms\n",
            "Speed: 7.8ms preprocess, 145.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 119.4ms\n",
            "Speed: 7.4ms preprocess, 119.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 161.5ms\n",
            "Speed: 4.3ms preprocess, 161.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 146.6ms\n",
            "Speed: 4.2ms preprocess, 146.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 144.3ms\n",
            "Speed: 8.4ms preprocess, 144.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.1ms\n",
            "Speed: 4.2ms preprocess, 137.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.8ms\n",
            "Speed: 3.5ms preprocess, 141.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 145.6ms\n",
            "Speed: 4.7ms preprocess, 145.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 188.5ms\n",
            "Speed: 3.4ms preprocess, 188.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 186.4ms\n",
            "Speed: 3.3ms preprocess, 186.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 184.7ms\n",
            "Speed: 3.5ms preprocess, 184.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 212.0ms\n",
            "Speed: 8.8ms preprocess, 212.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 208.8ms\n",
            "Speed: 3.4ms preprocess, 208.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 206.6ms\n",
            "Speed: 3.5ms preprocess, 206.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 218.8ms\n",
            "Speed: 7.9ms preprocess, 218.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 200.0ms\n",
            "Speed: 6.2ms preprocess, 200.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 210.9ms\n",
            "Speed: 8.3ms preprocess, 210.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 193.7ms\n",
            "Speed: 6.5ms preprocess, 193.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.2ms\n",
            "Speed: 8.6ms preprocess, 142.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 151.3ms\n",
            "Speed: 4.4ms preprocess, 151.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.3ms\n",
            "Speed: 5.1ms preprocess, 135.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 121.1ms\n",
            "Speed: 4.9ms preprocess, 121.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 164.1ms\n",
            "Speed: 5.9ms preprocess, 164.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 141.8ms\n",
            "Speed: 5.2ms preprocess, 141.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.2ms\n",
            "Speed: 7.2ms preprocess, 138.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 116.9ms\n",
            "Speed: 3.7ms preprocess, 116.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.5ms\n",
            "Speed: 4.5ms preprocess, 134.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.8ms\n",
            "Speed: 3.8ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 131.9ms\n",
            "Speed: 5.9ms preprocess, 131.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.4ms\n",
            "Speed: 5.5ms preprocess, 132.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 133.2ms\n",
            "Speed: 4.3ms preprocess, 133.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 134.5ms\n",
            "Speed: 3.7ms preprocess, 134.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 132.1ms\n",
            "Speed: 6.7ms preprocess, 132.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 117.5ms\n",
            "Speed: 4.8ms preprocess, 117.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.5ms\n",
            "Speed: 3.4ms preprocess, 139.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.8ms\n",
            "Speed: 3.2ms preprocess, 138.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 144.3ms\n",
            "Speed: 5.4ms preprocess, 144.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 118.2ms\n",
            "Speed: 3.5ms preprocess, 118.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 145.8ms\n",
            "Speed: 3.9ms preprocess, 145.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.0ms\n",
            "Speed: 7.5ms preprocess, 139.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.1ms\n",
            "Speed: 3.6ms preprocess, 135.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 123.6ms\n",
            "Speed: 3.3ms preprocess, 123.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 143.5ms\n",
            "Speed: 5.4ms preprocess, 143.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 158.8ms\n",
            "Speed: 4.0ms preprocess, 158.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 133.7ms\n",
            "Speed: 7.2ms preprocess, 133.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 124.3ms\n",
            "Speed: 3.9ms preprocess, 124.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 137.2ms\n",
            "Speed: 4.9ms preprocess, 137.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 135.3ms\n",
            "Speed: 3.4ms preprocess, 135.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.5ms\n",
            "Speed: 4.7ms preprocess, 138.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 121.4ms\n",
            "Speed: 7.1ms preprocess, 121.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 165.3ms\n",
            "Speed: 3.5ms preprocess, 165.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 197.4ms\n",
            "Speed: 7.1ms preprocess, 197.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 188.9ms\n",
            "Speed: 9.5ms preprocess, 188.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 183.4ms\n",
            "Speed: 3.3ms preprocess, 183.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 189.9ms\n",
            "Speed: 6.0ms preprocess, 189.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 223.1ms\n",
            "Speed: 3.2ms preprocess, 223.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 180.0ms\n",
            "Speed: 12.5ms preprocess, 180.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 187.6ms\n",
            "Speed: 3.4ms preprocess, 187.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 201.1ms\n",
            "Speed: 3.5ms preprocess, 201.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 204.4ms\n",
            "Speed: 12.1ms preprocess, 204.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 201.2ms\n",
            "Speed: 12.0ms preprocess, 201.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 115.3ms\n",
            "Speed: 4.7ms preprocess, 115.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 142.8ms\n",
            "Speed: 3.5ms preprocess, 142.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 139.6ms\n",
            "Speed: 11.1ms preprocess, 139.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 133.0ms\n",
            "Speed: 5.1ms preprocess, 133.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 117.1ms\n",
            "Speed: 4.0ms preprocess, 117.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.2ms\n",
            "Speed: 4.0ms preprocess, 138.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 159.9ms\n",
            "Speed: 5.1ms preprocess, 159.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 138.6ms\n",
            "Speed: 3.9ms preprocess, 138.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 face, 116.9ms\n",
            "Speed: 3.8ms preprocess, 116.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Video processed. events saved: 458\n"
          ]
        }
      ]
    }
  ]
}